import streamlit as st
import pandas as pd
import os
import sys
import subprocess
import tempfile
import zipfile
from pathlib import Path
import configparser
from datetime import datetime
import io
import json
import requests
import time
import hashlib
from typing import Dict, List, Any, Optional

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="CKAN Tools",
    page_icon="ğŸ› ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    .feature-card {
        background: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 5px solid #2563eb;
        margin: 1rem 0;
    }
    .success-box {
        background: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 5px;
        padding: 1rem;
        color: #155724;
    }
    .error-box {
        background: #f8d7da;
        border: 1px solid #f5c6cb;
        border-radius: 5px;
        padding: 1rem;
        color: #721c24;
    }
    .info-box {
        background: #d1ecf1;
        border: 1px solid #bee5eb;
        border-radius: 5px;
        padding: 1rem;
        color: #0c5460;
    }
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 8px;
        border: 1px solid #e5e7eb;
        text-align: center;
        box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    }
    .log-container {
        background: #1a1a1a;
        color: #00ff00;
        padding: 1rem;
        border-radius: 5px;
        font-family: 'Courier New', monospace;
        max-height: 300px;
        overflow-y: auto;
    }
</style>
""", unsafe_allow_html=True)

class CKANApi:
    """CKAN APIå®¢æˆ·ç«¯"""
    
    def __init__(self, base_url: str, api_key: str):
        self.base_url = base_url.rstrip('/')
        self.api_key = api_key
        self.session = requests.Session()
        self.session.headers.update({
            'Authorization': api_key,
            'Content-Type': 'application/json'
        })
    
    def test_connection(self) -> Dict[str, Any]:
        """æµ‹è¯•CKANè¿æ¥"""
        try:
            response = self.session.get(f"{self.base_url}/api/3/action/site_read")
            if response.status_code == 200:
                return {"success": True, "message": "è¿æ¥æˆåŠŸ"}
            else:
                return {"success": False, "message": f"HTTP {response.status_code}"}
        except Exception as e:
            return {"success": False, "message": str(e)}
    
    def create_dataset(self, dataset_data: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºæ•°æ®é›†"""
        try:
            response = self.session.post(
                f"{self.base_url}/api/3/action/package_create",
                json=dataset_data
            )
            return response.json()
        except Exception as e:
            return {"success": False, "error": {"message": str(e)}}
    
    def update_dataset(self, dataset_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ›´æ–°æ•°æ®é›†"""
        try:
            response = self.session.post(
                f"{self.base_url}/api/3/action/package_update",
                json=dataset_data
            )
            return response.json()
        except Exception as e:
            return {"success": False, "error": {"message": str(e)}}
    
    def get_dataset(self, dataset_id: str) -> Dict[str, Any]:
        """è·å–æ•°æ®é›†ä¿¡æ¯"""
        try:
            response = self.session.get(
                f"{self.base_url}/api/3/action/package_show?id={dataset_id}"
            )
            return response.json()
        except Exception as e:
            return {"success": False, "error": {"message": str(e)}}
    
    def list_datasets(self) -> Dict[str, Any]:
        """åˆ—å‡ºæ‰€æœ‰æ•°æ®é›†"""
        try:
            response = self.session.get(f"{self.base_url}/api/3/action/package_list")
            return response.json()
        except Exception as e:
            return {"success": False, "error": {"message": str(e)}}

class CKANToolsApp:
    def __init__(self):
        self.temp_dir = tempfile.mkdtemp()
        
        # åˆå§‹åŒ–session state
        if 'logs' not in st.session_state:
            st.session_state.logs = []
        if 'processing' not in st.session_state:
            st.session_state.processing = False
        
    def add_log(self, message: str, log_type: str = "info"):
        """æ·»åŠ æ—¥å¿—æ¶ˆæ¯"""
        timestamp = datetime.now().strftime('%H:%M:%S')
        log_entry = {
            'timestamp': timestamp,
            'message': message,
            'type': log_type
        }
        st.session_state.logs.append(log_entry)
        
        # åªä¿ç•™æœ€è¿‘50æ¡æ—¥å¿—
        if len(st.session_state.logs) > 50:
            st.session_state.logs = st.session_state.logs[-50:]
    
    def display_logs(self):
        """æ˜¾ç¤ºæ—¥å¿—"""
        if st.session_state.logs:
            st.subheader("ğŸ“‹ å¤„ç†æ—¥å¿—")
            
            log_container = st.container()
            with log_container:
                for log in st.session_state.logs[-10:]:  # æ˜¾ç¤ºæœ€è¿‘10æ¡
                    timestamp = log['timestamp']
                    message = log['message']
                    log_type = log['type']
                    
                    if log_type == "success":
                        st.success(f"[{timestamp}] âœ… {message}")
                    elif log_type == "error":
                        st.error(f"[{timestamp}] âŒ {message}")
                    elif log_type == "warning":
                        st.warning(f"[{timestamp}] âš ï¸ {message}")
                    else:
                        st.info(f"[{timestamp}] â„¹ï¸ {message}")
        
    def main(self):
        # ä¸»æ ‡é¢˜
        st.markdown("""
        <div class="main-header">
            <h1>ğŸ› ï¸ CKAN Tools</h1>
            <p>Excel Import & File Monitor - Webç‰ˆæœ¬</p>
        </div>
        """, unsafe_allow_html=True)
        
        # ä¾§è¾¹æ å¯¼èˆª
        with st.sidebar:
            st.image("https://via.placeholder.com/200x100/2563eb/ffffff?text=CKAN+Tools", 
                    caption="æ•°æ®ç®¡ç†å·¥å…·")
            
            tool_option = st.selectbox(
                "é€‰æ‹©å·¥å…·",
                ["ğŸ  é¦–é¡µ", "ğŸ“Š Excelå¯¼å…¥åˆ°CKAN", "ğŸ“ æ–‡ä»¶ç›‘æ§å™¨", "âš™ï¸ é…ç½®ç®¡ç†", "ğŸ“š ä½¿ç”¨è¯´æ˜"]
            )
            
            # å¿«é€ŸçŠ¶æ€æ£€æŸ¥
            if st.button("ğŸ” æ£€æŸ¥CKANè¿æ¥", use_container_width=True):
                self.quick_connection_test()
        
        # æ ¹æ®é€‰æ‹©æ˜¾ç¤ºä¸åŒé¡µé¢
        if tool_option == "ğŸ  é¦–é¡µ":
            self.show_home_page()
        elif tool_option == "ğŸ“Š Excelå¯¼å…¥åˆ°CKAN":
            self.show_excel_import_page()
        elif tool_option == "ğŸ“ æ–‡ä»¶ç›‘æ§å™¨":
            self.show_file_monitor_page()
        elif tool_option == "âš™ï¸ é…ç½®ç®¡ç†":
            self.show_config_page()
        elif tool_option == "ğŸ“š ä½¿ç”¨è¯´æ˜":
            self.show_help_page()
    
    def quick_connection_test(self):
        """å¿«é€Ÿè¿æ¥æµ‹è¯•"""
        ckan_url = st.session_state.get('ckan_url', '')
        api_key = st.session_state.get('api_key', '')
        
        if not ckan_url or not api_key:
            st.sidebar.error("è¯·å…ˆåœ¨é…ç½®é¡µé¢è®¾ç½®CKANè¿æ¥ä¿¡æ¯")
            return
        
        with st.sidebar:
            with st.spinner("æµ‹è¯•è¿æ¥ä¸­..."):
                api = CKANApi(ckan_url, api_key)
                result = api.test_connection()
                
                if result["success"]:
                    st.success("âœ… è¿æ¥æ­£å¸¸")
                else:
                    st.error(f"âŒ è¿æ¥å¤±è´¥: {result['message']}")
    
    def show_home_page(self):
        """æ˜¾ç¤ºé¦–é¡µ"""
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            <div class="feature-card">
                <h3>ğŸ“Š Excelå¯¼å…¥åˆ°CKAN</h3>
                <p>ä¸Šä¼ Excelæ–‡ä»¶ï¼Œè‡ªåŠ¨åˆ›å»ºæˆ–æ›´æ–°CKANæ•°æ®é›†ã€‚æ”¯æŒå¤šç§schemaæ ¼å¼ï¼ŒåŒ…æ‹¬datasetã€deviceã€digitaltwinç­‰ã€‚</p>
                <ul>
                    <li>è‡ªåŠ¨è§£æExcel schema</li>
                    <li>æ‰¹é‡åˆ›å»ºæ•°æ®é›†</li>
                    <li>å®æ—¶è¿›åº¦æ˜¾ç¤º</li>
                    <li>é”™è¯¯æ—¥å¿—è®°å½•</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown("""
            <div class="feature-card">
                <h3>ğŸ“ æ–‡ä»¶ç›‘æ§å™¨</h3>
                <p>ç›‘æ§æœ¬åœ°æ–‡ä»¶å˜åŒ–ï¼Œä¸CKANèµ„æºè¿›è¡Œå¯¹æ¯”ï¼Œæ£€æµ‹éœ€è¦åŒæ­¥çš„è¿‡æœŸæ–‡ä»¶ã€‚</p>
                <ul>
                    <li>å®æ—¶æ–‡ä»¶ç›‘æ§</li>
                    <li>ç‰ˆæœ¬å¯¹æ¯”åˆ†æ</li>
                    <li>åŒæ­¥å»ºè®®</li>
                    <li>è¯¦ç»†æŠ¥å‘Šç”Ÿæˆ</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)
        
        # å¿«é€Ÿå¼€å§‹
        st.subheader("ğŸš€ å¿«é€Ÿå¼€å§‹")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ“Š å¼€å§‹Excelå¯¼å…¥", use_container_width=True):
                st.rerun()
        
        with col2:
            if st.button("ğŸ“ å¯åŠ¨æ–‡ä»¶ç›‘æ§", use_container_width=True):
                st.rerun()
        
        with col3:
            if st.button("âš™ï¸ é…ç½®è®¾ç½®", use_container_width=True):
                st.rerun()
        
        # ä½¿ç”¨ç»Ÿè®¡
        self.show_usage_stats()
        
        # æœ€è¿‘æ´»åŠ¨
        self.show_recent_activity()
    
    def show_excel_import_page(self):
        """Excelå¯¼å…¥é¡µé¢"""
        st.header("ğŸ“Š Excelå¯¼å…¥åˆ°CKAN")
        
        # æ£€æŸ¥é…ç½®
        if not self.check_config():
            st.warning("âš ï¸ è¯·å…ˆåœ¨é…ç½®é¡µé¢è®¾ç½®CKANè¿æ¥ä¿¡æ¯")
            return
        
        # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
        st.subheader("1. ä¸Šä¼ Excelæ–‡ä»¶")
        uploaded_file = st.file_uploader(
            "é€‰æ‹©Excelæ–‡ä»¶",
            type=['xlsx', 'xls'],
            help="æ”¯æŒåŒ…å«datasetã€deviceã€digitaltwinç­‰schemaçš„Excelæ–‡ä»¶",
            key="excel_upload"
        )
        
        if uploaded_file is not None:
            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
            file_path = os.path.join(self.temp_dir, uploaded_file.name)
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            # æ–‡ä»¶ä¿¡æ¯
            file_size = len(uploaded_file.getbuffer()) / 1024 / 1024  # MB
            st.info(f"ğŸ“„ æ–‡ä»¶: {uploaded_file.name} ({file_size:.2f} MB)")
            
            # æ–‡ä»¶é¢„è§ˆ
            self.preview_excel_file(file_path)
            
            # å¯¼å…¥é€‰é¡¹
            st.subheader("2. å¯¼å…¥é€‰é¡¹")
            
            col1, col2 = st.columns(2)
            
            with col1:
                update_existing = st.checkbox("æ›´æ–°å·²å­˜åœ¨çš„æ•°æ®é›†", value=True)
                validate_data = st.checkbox("æ•°æ®éªŒè¯", value=True)
                
            with col2:
                batch_size = st.number_input("æ‰¹å¤„ç†å¤§å°", min_value=1, max_value=100, value=10)
                dry_run = st.checkbox("æ¨¡æ‹Ÿè¿è¡Œï¼ˆä¸å®é™…åˆ›å»ºï¼‰", value=False)
            
            # æ‰§è¡Œå¯¼å…¥
            st.subheader("3. æ‰§è¡Œå¯¼å…¥")
            
            col1, col2 = st.columns([3, 1])
            
            with col1:
                if st.button("ğŸš€ å¼€å§‹å¯¼å…¥", use_container_width=True, type="primary", 
                           disabled=st.session_state.processing):
                    self.execute_excel_import(
                        file_path, update_existing, validate_data, 
                        batch_size, dry_run
                    )
            
            with col2:
                if st.button("ğŸ—‘ï¸ æ¸…é™¤æ—¥å¿—", use_container_width=True):
                    st.session_state.logs = []
                    st.rerun()
        
        # æ˜¾ç¤ºæ—¥å¿—
        self.display_logs()
    
    def show_file_monitor_page(self):
        """æ–‡ä»¶ç›‘æ§é¡µé¢"""
        st.header("ğŸ“ æ–‡ä»¶ç›‘æ§å™¨")
        
        # æ£€æŸ¥é…ç½®
        if not self.check_config():
            st.warning("âš ï¸ è¯·å…ˆåœ¨é…ç½®é¡µé¢è®¾ç½®CKANè¿æ¥ä¿¡æ¯")
            return
        
        # ç›‘æ§é…ç½®
        st.subheader("1. ç›‘æ§é…ç½®")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.info("ğŸ’¡ ç”±äºWebç¯å¢ƒé™åˆ¶ï¼Œè¯·ä¸Šä¼ è¦ç›‘æ§çš„æ–‡ä»¶å¤¹å‹ç¼©åŒ…")
            uploaded_zip = st.file_uploader(
                "ä¸Šä¼ ç›‘æ§æ–‡ä»¶å¤¹(ZIPæ ¼å¼)",
                type=['zip'],
                help="å°†éœ€è¦ç›‘æ§çš„æ–‡ä»¶å¤¹å‹ç¼©ä¸ºZIPæ–‡ä»¶åä¸Šä¼ ",
                key="zip_upload"
            )
            
        with col2:
            dataset_filter = st.text_input(
                "æ•°æ®é›†åç§°è¿‡æ»¤å™¨ï¼ˆå¯é€‰ï¼‰",
                placeholder="ä¾‹å¦‚ï¼šsensor-data*",
                help="ä½¿ç”¨é€šé…ç¬¦è¿‡æ»¤è¦æ£€æŸ¥çš„æ•°æ®é›†"
            )
        
        # ç›‘æ§é€‰é¡¹
        st.subheader("2. ç›‘æ§é€‰é¡¹")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            check_metadata = st.checkbox("æ£€æŸ¥å…ƒæ•°æ®", value=True)
            check_size = st.checkbox("æ£€æŸ¥æ–‡ä»¶å¤§å°", value=True)
            
        with col2:
            check_timestamp = st.checkbox("æ£€æŸ¥æ—¶é—´æˆ³", value=True)
            check_hash = st.checkbox("æ£€æŸ¥æ–‡ä»¶å“ˆå¸Œ", value=False)
            
        with col3:
            debug_mode = st.checkbox("è°ƒè¯•æ¨¡å¼", value=False)
            detailed_report = st.checkbox("è¯¦ç»†æŠ¥å‘Š", value=True)
        
        # æ‰§è¡Œç›‘æ§
        st.subheader("3. æ‰§è¡Œç›‘æ§")
        
        if uploaded_zip is not None:
            zip_size = len(uploaded_zip.getbuffer()) / 1024 / 1024
            st.info(f"ğŸ“¦ ZIPæ–‡ä»¶: {uploaded_zip.name} ({zip_size:.2f} MB)")
            
            col1, col2 = st.columns([3, 1])
            
            with col1:
                if st.button("ğŸ” å¼€å§‹ç›‘æ§", use_container_width=True, type="primary",
                           disabled=st.session_state.processing):
                    self.execute_file_monitor(
                        uploaded_zip, dataset_filter, check_metadata, 
                        check_size, check_timestamp, check_hash, 
                        debug_mode, detailed_report
                    )
            
            with col2:
                if st.button("ğŸ—‘ï¸ æ¸…é™¤æ—¥å¿—", use_container_width=True):
                    st.session_state.logs = []
                    st.rerun()
        
        # display monitor history

        self.show_monitor_history()
        
        # æ˜¾ç¤ºæ—¥å¿—
        self.display_logs()
    
    def show_config_page(self):
        """é…ç½®ç®¡ç†é¡µé¢"""
        st.header("âš™ï¸ é…ç½®ç®¡ç†")
        
        # CKANè¿æ¥é…ç½®
        st.subheader("ğŸ”— CKANè¿æ¥é…ç½®")
        
        with st.form("ckan_config"):
            col1, col2 = st.columns(2)
            
            with col1:
                ckan_url = st.text_input(
                    "CKANæœåŠ¡å™¨URL",
                    value=st.session_state.get('ckan_url', ''),
                    placeholder="https://your-ckan-instance.com",
                    help="CKANå®ä¾‹çš„å®Œæ•´URLåœ°å€"
                )
                
                api_key = st.text_input(
                    "APIå¯†é’¥",
                    value=st.session_state.get('api_key', ''),
                    type="password",
                    help="åœ¨CKANç”¨æˆ·è®¾ç½®ä¸­å¯ä»¥æ‰¾åˆ°APIå¯†é’¥"
                )
                
            with col2:
                org_name = st.text_input(
                    "é»˜è®¤ç»„ç»‡",
                    value=st.session_state.get('org_name', ''),
                    placeholder="your-organization",
                    help="åˆ›å»ºæ•°æ®é›†æ—¶çš„é»˜è®¤ç»„ç»‡"
                )
                
                default_license = st.selectbox(
                    "é»˜è®¤è®¸å¯è¯",
                    ["cc-by", "cc-by-sa", "cc-zero", "odc-pddl", "other-open"],
                    index=0,
                    help="æ–°æ•°æ®é›†çš„é»˜è®¤è®¸å¯è¯ç±»å‹"
                )
            
            # é«˜çº§è®¾ç½®
            st.subheader("ğŸ”§ é«˜çº§è®¾ç½®")
            
            col1, col2 = st.columns(2)
            
            with col1:
                request_timeout = st.number_input(
                    "è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)",
                    min_value=10,
                    max_value=300,
                    value=st.session_state.get('request_timeout', 60)
                )
                
            with col2:
                max_retries = st.number_input(
                    "æœ€å¤§é‡è¯•æ¬¡æ•°",
                    min_value=0,
                    max_value=10,
                    value=st.session_state.get('max_retries', 3)
                )
            
            # æŒ‰é’®
            col1, col2 = st.columns(2)
            
            with col1:
                test_connection = st.form_submit_button("ğŸ”§ æµ‹è¯•è¿æ¥", use_container_width=True)
                
            with col2:
                save_config = st.form_submit_button("ğŸ’¾ ä¿å­˜é…ç½®", use_container_width=True, type="primary")
            
            # å¤„ç†è¡¨å•æäº¤
            if test_connection:
                self.test_ckan_connection(ckan_url, api_key)
                
            if save_config:
                # ä¿å­˜é…ç½®åˆ°session state
                st.session_state.update({
                    'ckan_url': ckan_url,
                    'api_key': api_key,
                    'org_name': org_name,
                    'default_license': default_license,
                    'request_timeout': request_timeout,
                    'max_retries': max_retries
                })
                st.success("âœ… é…ç½®å·²ä¿å­˜")
                self.add_log("é…ç½®å·²æ›´æ–°", "success")
        
        # é…ç½®å¯¼å…¥/å¯¼å‡º
        st.subheader("ğŸ“‹ é…ç½®å¯¼å…¥/å¯¼å‡º")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ“¤ å¯¼å‡ºé…ç½®", use_container_width=True):
                config_data = {
                    'ckan_url': st.session_state.get('ckan_url', ''),
                    'org_name': st.session_state.get('org_name', ''),
                    'default_license': st.session_state.get('default_license', 'cc-by'),
                    'request_timeout': st.session_state.get('request_timeout', 60),
                    'max_retries': st.session_state.get('max_retries', 3)
                }
                
                config_json = json.dumps(config_data, indent=2, ensure_ascii=False)
                st.download_button(
                    label="ğŸ’¾ ä¸‹è½½é…ç½®æ–‡ä»¶",
                    data=config_json,
                    file_name="ckan_tools_config.json",
                    mime="application/json"
                )
        
        with col2:
            uploaded_config = st.file_uploader(
                "ğŸ“¥ å¯¼å…¥é…ç½®æ–‡ä»¶",
                type=['json'],
                help="ä¸Šä¼ ä¹‹å‰å¯¼å‡ºçš„é…ç½®æ–‡ä»¶"
            )
            
            if uploaded_config:
                try:
                    config_data = json.load(uploaded_config)
                    st.session_state.update(config_data)
                    st.success("âœ… é…ç½®å·²å¯¼å…¥")
                    self.add_log("é…ç½®æ–‡ä»¶å·²å¯¼å…¥", "success")
                    st.rerun()
                except Exception as e:
                    st.error(f"âŒ å¯¼å…¥é…ç½®å¤±è´¥: {str(e)}")
    
    def show_help_page(self):
        """ä½¿ç”¨è¯´æ˜é¡µé¢"""
        st.header("ğŸ“š ä½¿ç”¨è¯´æ˜")
        
        # å¿«é€Ÿå…¥é—¨
        with st.expander("ğŸš€ å¿«é€Ÿå…¥é—¨", expanded=True):
            st.markdown("""
            ### 1. Excelå¯¼å…¥åˆ°CKAN
            
            **æ­¥éª¤:**
            1. åœ¨ä¾§è¾¹æ é€‰æ‹©"ğŸ“Š Excelå¯¼å…¥åˆ°CKAN"
            2. ä¸Šä¼ åŒ…å«æ•°æ®é›†ä¿¡æ¯çš„Excelæ–‡ä»¶
            3. é…ç½®CKANæœåŠ¡å™¨URLå’ŒAPIå¯†é’¥
            4. é¢„è§ˆè¦å¯¼å…¥çš„æ•°æ®
            5. ç‚¹å‡»"å¼€å§‹å¯¼å…¥"æŒ‰é’®
            
            **Excelæ–‡ä»¶æ ¼å¼è¦æ±‚:**
            - æ”¯æŒ.xlsxå’Œ.xlsæ ¼å¼
            - æ¯ä¸ªå·¥ä½œè¡¨ä»£è¡¨ä¸€ç§schemaç±»å‹(datasetã€deviceã€digitaltwinç­‰)
            - ç¬¬ä¸€è¡Œåº”ä¸ºåˆ—æ ‡é¢˜
            - å¿…éœ€å­—æ®µï¼šname(åç§°)ã€title(æ ‡é¢˜)
            
            **å¸¸ç”¨å­—æ®µè¯´æ˜:**
            - `name`: æ•°æ®é›†å”¯ä¸€æ ‡è¯†ç¬¦ï¼ˆå¿…éœ€ï¼‰
            - `title`: æ•°æ®é›†æ ‡é¢˜ï¼ˆå¿…éœ€ï¼‰
            - `notes`: æ•°æ®é›†æè¿°
            - `owner_org`: æ‰€å±ç»„ç»‡
            - `tags`: æ ‡ç­¾ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰
            - `license_id`: è®¸å¯è¯ç±»å‹
            
            ---
            
            ### 2. æ–‡ä»¶ç›‘æ§å™¨
            
            **æ­¥éª¤:**
            1. åœ¨ä¾§è¾¹æ é€‰æ‹©"ğŸ“ æ–‡ä»¶ç›‘æ§å™¨"
            2. ä¸Šä¼ è¦ç›‘æ§çš„æ–‡ä»¶å¤¹å‹ç¼©åŒ…
            3. é…ç½®CKANè¿æ¥ä¿¡æ¯
            4. é€‰æ‹©ç›‘æ§é€‰é¡¹
            5. ç‚¹å‡»"å¼€å§‹ç›‘æ§"æŒ‰é’®
            
            **ç›‘æ§åŠŸèƒ½:**
            - æ–‡ä»¶ä¿®æ”¹æ—¶é—´å¯¹æ¯”
            - æ–‡ä»¶å¤§å°å˜åŒ–æ£€æµ‹
            - å…ƒæ•°æ®ä¸€è‡´æ€§æ£€æŸ¥
            - ç”ŸæˆåŒæ­¥å»ºè®®æŠ¥å‘Š
            """)
        
        # å¸¸è§é—®é¢˜
        with st.expander("â“ å¸¸è§é—®é¢˜"):
            st.markdown("""
            **Q: å¦‚ä½•è·å–CKAN APIå¯†é’¥?**
            
            A: ç™»å½•æ‚¨çš„CKANå®ä¾‹ï¼Œè¿›å…¥ç”¨æˆ·è®¾ç½®é¡µé¢ï¼Œåœ¨"API Key"éƒ¨åˆ†å¯ä»¥æ‰¾åˆ°æˆ–ç”Ÿæˆæ–°çš„å¯†é’¥ã€‚
            
            **Q: Excelæ–‡ä»¶åº”è¯¥åŒ…å«å“ªäº›å­—æ®µ?**
            
            A: åŸºæœ¬å¿…éœ€å­—æ®µåŒ…æ‹¬ï¼š
            - `name`: æ•°æ®é›†å”¯ä¸€æ ‡è¯†ç¬¦
            - `title`: æ•°æ®é›†æ ‡é¢˜
            - `notes`: æ•°æ®é›†æè¿°(å¯é€‰)
            - `owner_org`: æ‰€å±ç»„ç»‡(å¯é€‰)
            
            **Q: ä¸ºä»€ä¹ˆæ–‡ä»¶ç›‘æ§éœ€è¦ä¸Šä¼ ZIPæ–‡ä»¶?**
            
            A: ç”±äºWebåº”ç”¨çš„å®‰å…¨é™åˆ¶ï¼Œæ— æ³•ç›´æ¥è®¿é—®ç”¨æˆ·æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿã€‚é€šè¿‡ä¸Šä¼ ZIPæ–‡ä»¶çš„æ–¹å¼å¯ä»¥åœ¨äº‘ç«¯æ¨¡æ‹Ÿæ–‡ä»¶ç›‘æ§åŠŸèƒ½ã€‚
            
            **Q: å¤„ç†å¤§æ–‡ä»¶æ—¶åº”è¯¥æ³¨æ„ä»€ä¹ˆ?**
            
            A: å»ºè®®ï¼š
            - å°†å¤§æ–‡ä»¶åˆ†æ‰¹å¤„ç†
            - ä½¿ç”¨è¾ƒå°çš„æ‰¹å¤„ç†å¤§å°
            - å¢åŠ è¶…æ—¶æ—¶é—´è®¾ç½®
            - åœ¨ç½‘ç»œçŠ¶å†µè‰¯å¥½æ—¶è¿›è¡Œæ“ä½œ
            
            **Q: å¦‚ä½•å¤„ç†å¯¼å…¥é”™è¯¯?**
            
            A: å¸¸è§é”™è¯¯è§£å†³æ–¹æ¡ˆï¼š
            - åç§°å†²çªï¼šæ£€æŸ¥æ•°æ®é›†åç§°æ˜¯å¦å·²å­˜åœ¨
            - æƒé™ä¸è¶³ï¼šç¡®è®¤APIå¯†é’¥æœ‰ç›¸åº”æƒé™
            - æ ¼å¼é”™è¯¯ï¼šæ£€æŸ¥Excelæ–‡ä»¶æ ¼å¼å’Œå­—æ®µåç§°
            - ç½‘ç»œè¶…æ—¶ï¼šå¢åŠ è¶…æ—¶æ—¶é—´æˆ–åˆ†æ‰¹å¤„ç†
            """)
        
        # APIæ–‡æ¡£
        with st.expander("ğŸ”§ æŠ€æœ¯è¯´æ˜"):
            st.markdown("""
            ### CKAN APIç«¯ç‚¹
            
            æœ¬å·¥å…·ä½¿ç”¨ä»¥ä¸‹CKAN APIç«¯ç‚¹ï¼š
            
            - `package_create`: åˆ›å»ºæ–°æ•°æ®é›†
            - `package_update`: æ›´æ–°å·²å­˜åœ¨çš„æ•°æ®é›†
            - `package_show`: è·å–æ•°æ®é›†ä¿¡æ¯
            - `package_list`: åˆ—å‡ºæ‰€æœ‰æ•°æ®é›†
            - `resource_create`: åˆ›å»ºèµ„æº
            - `resource_update`: æ›´æ–°èµ„æº
            
            ### é”™è¯¯ä»£ç è¯´æ˜
            
            - `200`: æ“ä½œæˆåŠŸ
            - `400`: è¯·æ±‚å‚æ•°é”™è¯¯
            - `401`: è®¤è¯å¤±è´¥ï¼Œæ£€æŸ¥APIå¯†é’¥
            - `403`: æƒé™ä¸è¶³
            - `404`: èµ„æºä¸å­˜åœ¨
            - `409`: èµ„æºå†²çªï¼ˆå¦‚åç§°é‡å¤ï¼‰
            - `500`: æœåŠ¡å™¨å†…éƒ¨é”™è¯¯
            
            ### æ•°æ®éªŒè¯è§„åˆ™
            
            - æ•°æ®é›†åç§°åªèƒ½åŒ…å«å°å†™å­—æ¯ã€æ•°å­—ã€è¿å­—ç¬¦å’Œä¸‹åˆ’çº¿
            - åç§°é•¿åº¦ä¸èƒ½è¶…è¿‡100ä¸ªå­—ç¬¦
            - æ ‡é¢˜ä¸èƒ½ä¸ºç©º
            - ç»„ç»‡åç§°å¿…é¡»å­˜åœ¨äºCKANä¸­
            """)
        
        # ç¤ºä¾‹æ–‡ä»¶
        with st.expander("ğŸ“„ ç¤ºä¾‹æ–‡ä»¶"):
            st.markdown("### Excelæ–‡ä»¶ç¤ºä¾‹")
            
            # åˆ›å»ºç¤ºä¾‹æ•°æ®
            sample_data = pd.DataFrame({
                'name': ['sensor-data-2024', 'weather-station-alpha', 'traffic-monitor-001'],
                'title': ['ä¼ æ„Ÿå™¨æ•°æ®2024', 'å¤©æ°”ç«™Alphaæ•°æ®', 'äº¤é€šç›‘æ§ç‚¹001'],
                'notes': ['2024å¹´ä¼ æ„Ÿå™¨é‡‡é›†æ•°æ®', 'å¤©æ°”ç«™Alphaçš„æ°”è±¡æ•°æ®', 'äº¤é€šç›‘æ§ç‚¹çš„è½¦æµæ•°æ®'],
                'tags': ['sensor,data,2024', 'weather,climate', 'traffic,monitoring'],
                'license_id': ['cc-by', 'cc-by-sa', 'cc-zero']
            })
            
            st.dataframe(sample_data, use_container_width=True)
            
            # æä¾›ä¸‹è½½ç¤ºä¾‹æ–‡ä»¶
            excel_buffer = io.BytesIO()
            with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                sample_data.to_excel(writer, sheet_name='dataset', index=False)
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½ç¤ºä¾‹Excelæ–‡ä»¶",
                data=excel_buffer.getvalue(),
                file_name="ckan_tools_example.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        
        # è”ç³»ä¿¡æ¯
        st.subheader("ğŸ“ æ”¯æŒä¸åé¦ˆ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.info("""
            **é‡åˆ°é—®é¢˜ï¼Ÿ**
            
            - æ£€æŸ¥ç½‘ç»œè¿æ¥
            - éªŒè¯CKANæœåŠ¡å™¨çŠ¶æ€
            - ç¡®è®¤APIå¯†é’¥æœ‰æ•ˆæ€§
            - æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—
            - å°è¯•ä½¿ç”¨ç¤ºä¾‹æ–‡ä»¶æµ‹è¯•
            """)
        
        with col2:
            st.success("""
            **åé¦ˆæ¸ é“**
            
            - æäº¤GitHub Issue
            - å‘é€é‚®ä»¶åé¦ˆ
            - åŠ å…¥ç”¨æˆ·è®¨è®ºç¾¤
            - æŸ¥çœ‹åœ¨çº¿æ–‡æ¡£
            - å‚ä¸åŠŸèƒ½å»ºè®®è®¨è®º
            """)
    
    def check_config(self) -> bool:
        """æ£€æŸ¥CKANé…ç½®æ˜¯å¦å®Œæ•´"""
        return bool(st.session_state.get('ckan_url') and st.session_state.get('api_key'))
    
    def preview_excel_file(self, file_path: str):
        """é¢„è§ˆExcelæ–‡ä»¶å†…å®¹"""
        try:
            excel_data = pd.ExcelFile(file_path)
            sheet_names = excel_data.sheet_names
            
            st.subheader("ğŸ“‹ æ–‡ä»¶é¢„è§ˆ")
            
            # æ˜¾ç¤ºå·¥ä½œè¡¨é€‰æ‹©
            selected_sheets = st.multiselect(
                "é€‰æ‹©è¦å¤„ç†çš„å·¥ä½œè¡¨",
                sheet_names,
                default=sheet_names,
                help="é€‰æ‹©è¦å¯¼å…¥åˆ°CKANçš„å·¥ä½œè¡¨"
            )
            
            # é¢„è§ˆé€‰ä¸­çš„å·¥ä½œè¡¨
            for sheet in selected_sheets:
                with st.expander(f"ğŸ“Š é¢„è§ˆ: {sheet}", expanded=len(selected_sheets) == 1):
                    df = pd.read_excel(file_path, sheet_name=sheet)
                    
                    # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("æ€»è¡Œæ•°", len(df))
                    with col2:
                        st.metric("æ€»åˆ—æ•°", len(df.columns))
                    with col3:
                        st.metric("æœ‰æ•ˆæ•°æ®è¡Œ", len(df.dropna()))
                    
                    # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
                    st.dataframe(df.head(10), use_container_width=True)
                    
                    # æ£€æŸ¥å¿…éœ€å­—æ®µ
                    required_fields = ['name', 'title']
                    missing_fields = [field for field in required_fields if field not in df.columns]
                    
                    if missing_fields:
                        st.warning(f"âš ï¸ ç¼ºå°‘å¿…éœ€å­—æ®µ: {', '.join(missing_fields)}")
                    else:
                        st.success("âœ… åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µ")
                        
        except Exception as e:
            st.error(f"âŒ é¢„è§ˆæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
    
    def test_ckan_connection(self, ckan_url: str, api_key: str):
        """æµ‹è¯•CKANè¿æ¥"""
        if not ckan_url or not api_key:
            st.error("âŒ è¯·å¡«å†™CKAN URLå’ŒAPIå¯†é’¥")
            return
        
        with st.spinner("ğŸ”„ æ­£åœ¨æµ‹è¯•è¿æ¥..."):
            try:
                api = CKANApi(ckan_url, api_key)
                result = api.test_connection()
                
                if result["success"]:
                    st.success("âœ… CKANè¿æ¥æµ‹è¯•æˆåŠŸï¼")
                    st.info(f"ğŸŒ æœåŠ¡å™¨: {ckan_url}")
                    st.info("ğŸ”‘ APIå¯†é’¥éªŒè¯é€šè¿‡")
                    self.add_log("CKANè¿æ¥æµ‹è¯•æˆåŠŸ", "success")
                else:
                    st.error(f"âŒ è¿æ¥æµ‹è¯•å¤±è´¥: {result['message']}")
                    self.add_log(f"CKANè¿æ¥æµ‹è¯•å¤±è´¥: {result['message']}", "error")
                    
            except Exception as e:
                st.error(f"âŒ è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
                self.add_log(f"CKANè¿æ¥æµ‹è¯•å¼‚å¸¸: {str(e)}", "error")
    
    def execute_excel_import(self, file_path: str, update_existing: bool, 
                           validate_data: bool, batch_size: int, dry_run: bool):
        """æ‰§è¡ŒExcelå¯¼å…¥"""
        st.session_state.processing = True
        
        # åˆ›å»ºè¿›åº¦æ˜¾ç¤º
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            self.add_log("å¼€å§‹Excelå¯¼å…¥ä»»åŠ¡", "info")
            status_text.text("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–...")
            
            # è·å–CKAN APIå®¢æˆ·ç«¯
            api = CKANApi(st.session_state.ckan_url, st.session_state.api_key)
            
            # è¯»å–Excelæ–‡ä»¶
            excel_data = pd.ExcelFile(file_path)
            total_sheets = len(excel_data.sheet_names)
            
            self.add_log(f"å‘ç° {total_sheets} ä¸ªå·¥ä½œè¡¨", "info")
            progress_bar.progress(10)
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_processed = 0
            total_success = 0
            total_errors = 0
            
            # å¤„ç†æ¯ä¸ªå·¥ä½œè¡¨
            for sheet_idx, sheet_name in enumerate(excel_data.sheet_names):
                status_text.text(f"ğŸ”„ æ­£åœ¨å¤„ç†å·¥ä½œè¡¨: {sheet_name}")
                sheet_progress = 10 + (sheet_idx / total_sheets) * 80
                progress_bar.progress(int(sheet_progress))
                
                try:
                    # è¯»å–å·¥ä½œè¡¨æ•°æ®
                    df = pd.read_excel(file_path, sheet_name=sheet_name)
                    self.add_log(f"å¤„ç†å·¥ä½œè¡¨ '{sheet_name}': {len(df)} è¡Œæ•°æ®", "info")
                    
                    # éªŒè¯æ•°æ®
                    if validate_data:
                        validation_errors = self.validate_dataset_data(df)
                        if validation_errors:
                            for error in validation_errors[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªé”™è¯¯
                                self.add_log(f"æ•°æ®éªŒè¯é”™è¯¯: {error}", "warning")
                            if not dry_run:
                                continue
                    
                    # å¤„ç†æ¯ä¸€è¡Œæ•°æ®
                    for idx, row in df.iterrows():
                        if pd.isna(row.get('name')) or pd.isna(row.get('title')):
                            continue  # è·³è¿‡ç¼ºå°‘å¿…éœ€å­—æ®µçš„è¡Œ
                        
                        dataset_data = self.prepare_dataset_data(row, sheet_name)
                        total_processed += 1
                        
                        if dry_run:
                            self.add_log(f"[æ¨¡æ‹Ÿ] å‡†å¤‡åˆ›å»ºæ•°æ®é›†: {dataset_data['name']}", "info")
                            total_success += 1
                        else:
                            # æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å·²å­˜åœ¨
                            existing = api.get_dataset(dataset_data['name'])
                            
                            if existing.get('success'):
                                if update_existing:
                                    result = api.update_dataset(dataset_data)
                                    action = "æ›´æ–°"
                                else:
                                    self.add_log(f"æ•°æ®é›†å·²å­˜åœ¨ï¼Œè·³è¿‡: {dataset_data['name']}", "warning")
                                    continue
                            else:
                                result = api.create_dataset(dataset_data)
                                action = "åˆ›å»º"
                            
                            if result.get('success'):
                                self.add_log(f"{action}æ•°æ®é›†æˆåŠŸ: {dataset_data['name']}", "success")
                                total_success += 1
                            else:
                                error_msg = result.get('error', {}).get('message', 'æœªçŸ¥é”™è¯¯')
                                self.add_log(f"{action}æ•°æ®é›†å¤±è´¥: {dataset_data['name']} - {error_msg}", "error")
                                total_errors += 1
                        
                        # æ‰¹å¤„ç†ä¼‘æ¯
                        if total_processed % batch_size == 0:
                            time.sleep(0.1)  # é¿å…è¿‡äºé¢‘ç¹çš„APIè°ƒç”¨
                
                except Exception as e:
                    self.add_log(f"å¤„ç†å·¥ä½œè¡¨ '{sheet_name}' æ—¶å‡ºé”™: {str(e)}", "error")
                    total_errors += 1
            
            # å®Œæˆå¤„ç†
            progress_bar.progress(100)
            status_text.text("âœ… Excelå¯¼å…¥å®Œæˆï¼")
            
            # æ˜¾ç¤ºæ‘˜è¦
            self.add_log("Excelå¯¼å…¥ä»»åŠ¡å®Œæˆ", "success")
            self.add_log(f"æ€»è®¡å¤„ç†: {total_processed}, æˆåŠŸ: {total_success}, é”™è¯¯: {total_errors}", "info")
            
            # æ˜¾ç¤ºç»“æœæ‘˜è¦
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æ€»è®¡å¤„ç†", total_processed)
            with col2:
                st.metric("æˆåŠŸ", total_success, f"+{total_success}")
            with col3:
                st.metric("é”™è¯¯", total_errors, f"+{total_errors}" if total_errors > 0 else None)
            
            if dry_run:
                st.info("ğŸ§ª è¿™æ˜¯æ¨¡æ‹Ÿè¿è¡Œï¼Œæ²¡æœ‰å®é™…åˆ›å»ºæ•°æ®é›†")
            else:
                st.success("ğŸ‰ Excelå¯¼å…¥ä»»åŠ¡å®Œæˆï¼")
            
            # ç”ŸæˆæŠ¥å‘Š
            self.generate_import_report(total_processed, total_success, total_errors, dry_run)
            
        except Exception as e:
            progress_bar.progress(0)
            status_text.text("âŒ å¯¼å…¥è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯")
            st.error(f"é”™è¯¯è¯¦æƒ…: {str(e)}")
            self.add_log(f"å¯¼å…¥ä»»åŠ¡å¼‚å¸¸: {str(e)}", "error")
        
        finally:
            st.session_state.processing = False
    
    def validate_dataset_data(self, df: pd.DataFrame) -> List[str]:
        """éªŒè¯æ•°æ®é›†æ•°æ®"""
        errors = []
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        required_fields = ['name', 'title']
        for field in required_fields:
            if field not in df.columns:
                errors.append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
        
        # æ£€æŸ¥æ•°æ®è´¨é‡
        if 'name' in df.columns:
            # æ£€æŸ¥åç§°æ ¼å¼
            invalid_names = df[df['name'].str.contains(r'[^a-z0-9\-_]', na=False)]
            if not invalid_names.empty:
                errors.append(f"å‘ç° {len(invalid_names)} ä¸ªæ— æ•ˆçš„æ•°æ®é›†åç§°ï¼ˆåªèƒ½åŒ…å«å°å†™å­—æ¯ã€æ•°å­—ã€è¿å­—ç¬¦å’Œä¸‹åˆ’çº¿ï¼‰")
        
        return errors
    
    def prepare_dataset_data(self, row: pd.Series, schema_type: str) -> Dict[str, Any]:
        """å‡†å¤‡æ•°æ®é›†æ•°æ®"""
        # åŸºæœ¬æ•°æ®é›†ä¿¡æ¯
        dataset_data = {
            'name': str(row['name']).lower().replace(' ', '-'),
            'title': str(row['title']),
            'type': schema_type
        }
        
        # å¯é€‰å­—æ®µ
        optional_fields = {
            'notes': 'notes',
            'owner_org': 'owner_org',
            'license_id': 'license_id',
            'url': 'url',
            'version': 'version',
            'author': 'author',
            'author_email': 'author_email',
            'maintainer': 'maintainer',
            'maintainer_email': 'maintainer_email'
        }
        
        for excel_field, ckan_field in optional_fields.items():
            if excel_field in row and pd.notna(row[excel_field]):
                dataset_data[ckan_field] = str(row[excel_field])
        
        # å¤„ç†æ ‡ç­¾
        if 'tags' in row and pd.notna(row['tags']):
            tags = [tag.strip() for tag in str(row['tags']).split(',')]
            dataset_data['tags'] = [{'name': tag} for tag in tags if tag]
        
        # æ·»åŠ é»˜è®¤å€¼
        if 'owner_org' not in dataset_data and st.session_state.get('org_name'):
            dataset_data['owner_org'] = st.session_state.org_name
        
        if 'license_id' not in dataset_data:
            dataset_data['license_id'] = st.session_state.get('default_license', 'cc-by')
        
        return dataset_data
    
    def execute_file_monitor(self, uploaded_zip, dataset_filter: str, 
                           check_metadata: bool, check_size: bool, 
                           check_timestamp: bool, check_hash: bool, 
                           debug_mode: bool, detailed_report: bool):
        """æ‰§è¡Œæ–‡ä»¶ç›‘æ§"""
        st.session_state.processing = True
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            self.add_log("å¼€å§‹æ–‡ä»¶ç›‘æ§ä»»åŠ¡", "info")
            status_text.text("ğŸ”„ æ­£åœ¨è§£å‹æ–‡ä»¶...")
            progress_bar.progress(20)
            
            # è§£å‹ZIPæ–‡ä»¶
            zip_path = os.path.join(self.temp_dir, uploaded_zip.name)
            with open(zip_path, "wb") as f:
                f.write(uploaded_zip.getbuffer())
            
            extracted_dir = os.path.join(self.temp_dir, "extracted")
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(extracted_dir)
                file_list = zip_ref.namelist()
            
            self.add_log(f"è§£å‹å®Œæˆï¼Œå‘ç° {len(file_list)} ä¸ªæ–‡ä»¶", "info")
            progress_bar.progress(40)
            
            # è·å–CKANæ•°æ®
            status_text.text("ğŸ” æ­£åœ¨è·å–CKANæ•°æ®...")
            api = CKANApi(st.session_state.ckan_url, st.session_state.api_key)
            
            datasets_result = api.list_datasets()
            if not datasets_result.get('success'):
                raise Exception("æ— æ³•è·å–CKANæ•°æ®é›†åˆ—è¡¨")
            
            dataset_names = datasets_result['result']
            if dataset_filter:
                # ç®€å•çš„é€šé…ç¬¦è¿‡æ»¤
                import fnmatch
                dataset_names = [name for name in dataset_names 
                               if fnmatch.fnmatch(name, dataset_filter)]
            
            self.add_log(f"æ‰¾åˆ° {len(dataset_names)} ä¸ªæ•°æ®é›†è¿›è¡Œç›‘æ§", "info")
            progress_bar.progress(60)
            
            # åˆ†ææ–‡ä»¶
            status_text.text("ğŸ“Š æ­£åœ¨åˆ†ææ–‡ä»¶å·®å¼‚...")
            outdated_files = []
            
            # éå†æœ¬åœ°æ–‡ä»¶
            for root, dirs, files in os.walk(extracted_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    relative_path = os.path.relpath(file_path, extracted_dir)
                    
                    # æ¨¡æ‹Ÿæ–‡ä»¶åˆ†æï¼ˆåœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šæ¯”è¾ƒæ–‡ä»¶ä¸CKANèµ„æºï¼‰
                    file_stat = os.stat(file_path)
                    file_size = file_stat.st_size
                    file_mtime = datetime.fromtimestamp(file_stat.st_mtime)
                    
                    # æ¨¡æ‹Ÿæ£€æµ‹è¿‡æœŸæ–‡ä»¶ï¼ˆå®é™…ä¸­ä¼šè°ƒç”¨CKAN APIæ¯”è¾ƒï¼‰
                    if len(outdated_files) < 5:  # é™åˆ¶æ¼”ç¤ºæ•°é‡
                        if file_size > 1024:  # å¤§äº1KBçš„æ–‡ä»¶
                            reason = []
                            if check_timestamp:
                                reason.append("æœ¬åœ°æ–‡ä»¶æ›´æ–°")
                            if check_size:
                                reason.append("æ–‡ä»¶å¤§å°å˜åŒ–")
                            if check_metadata:
                                reason.append("å…ƒæ•°æ®ä¸åŒ¹é…")
                            
                            outdated_files.append({
                                'file': relative_path,
                                'reason': ', '.join(reason),
                                'local_size': file_size,
                                'local_modified': file_mtime.strftime('%Y-%m-%d %H:%M:%S'),
                                'ckan_modified': '2024-01-01 10:00:00',  # æ¨¡æ‹ŸCKANæ—¶é—´
                                'dataset': 'example-dataset'  # æ¨¡æ‹Ÿå…³è”æ•°æ®é›†
                            })
            
            progress_bar.progress(90)
            status_text.text("ğŸ“‹ æ­£åœ¨ç”ŸæˆæŠ¥å‘Š...")
            
            # ç”Ÿæˆç›‘æ§æŠ¥å‘Š
            self.generate_monitor_report(outdated_files, detailed_report)
            
            progress_bar.progress(100)
            status_text.text("âœ… æ–‡ä»¶ç›‘æ§å®Œæˆï¼")
            
            self.add_log("æ–‡ä»¶ç›‘æ§ä»»åŠ¡å®Œæˆ", "success")
            self.add_log(f"å‘ç° {len(outdated_files)} ä¸ªéœ€è¦åŒæ­¥çš„æ–‡ä»¶", 
                        "warning" if outdated_files else "success")
            
        except Exception as e:
            progress_bar.progress(0)
            status_text.text("âŒ ç›‘æ§è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯")
            st.error(f"é”™è¯¯è¯¦æƒ…: {str(e)}")
            self.add_log(f"ç›‘æ§ä»»åŠ¡å¼‚å¸¸: {str(e)}", "error")
        
        finally:
            st.session_state.processing = False
    
    def generate_import_report(self, total_processed: int, total_success: int, 
                             total_errors: int, dry_run: bool):
        """ç”Ÿæˆå¯¼å…¥æŠ¥å‘Š"""
        report_data = {
            'timestamp': datetime.now().isoformat(),
            'type': 'excel_import',
            'mode': 'dry_run' if dry_run else 'live',
            'summary': {
                'total_processed': total_processed,
                'total_success': total_success,
                'total_errors': total_errors,
                'success_rate': f"{(total_success/total_processed*100):.1f}%" if total_processed > 0 else "0%"
            },
            'logs': st.session_state.logs[-20:]  # æœ€è¿‘20æ¡æ—¥å¿—
        }
        
        report_json = json.dumps(report_data, indent=2, ensure_ascii=False)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½è¯¦ç»†æŠ¥å‘Š",
                data=report_json,
                file_name=f"excel_import_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
        
        with col2:
            # ç”Ÿæˆç®€åŒ–çš„CSVæŠ¥å‘Š
            if st.session_state.logs:
                log_df = pd.DataFrame([
                    {
                        'timestamp': log['timestamp'],
                        'type': log['type'],
                        'message': log['message']
                    }
                    for log in st.session_state.logs[-20:]
                ])
                
                csv_data = log_df.to_csv(index=False)
                st.download_button(
                    label="ğŸ“Š ä¸‹è½½æ—¥å¿—CSV",
                    data=csv_data,
                    file_name=f"import_logs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
    
    def generate_monitor_report(self, outdated_files: List[Dict], detailed_report: bool):
        """ç”Ÿæˆç›‘æ§æŠ¥å‘Š"""
        if outdated_files:
            st.warning(f"âš ï¸ å‘ç° {len(outdated_files)} ä¸ªéœ€è¦åŒæ­¥çš„æ–‡ä»¶")
            
            # æ˜¾ç¤ºç»“æœè¡¨æ ¼
            df_results = pd.DataFrame(outdated_files)
            st.dataframe(df_results, use_container_width=True)
            
            # åŒæ­¥å»ºè®®
            st.subheader("ğŸ”§ åŒæ­¥å»ºè®®")
            for file_info in outdated_files:
                with st.expander(f"ğŸ“„ {file_info['file']}"):
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.write("**æ–‡ä»¶ä¿¡æ¯:**")
                        st.write(f"- æœ¬åœ°å¤§å°: {file_info['local_size']} å­—èŠ‚")
                        st.write(f"- æœ¬åœ°ä¿®æ”¹æ—¶é—´: {file_info['local_modified']}")
                        st.write(f"- å…³è”æ•°æ®é›†: {file_info['dataset']}")
                    
                    with col2:
                        st.write("**å»ºè®®æ“ä½œ:**")
                        st.write(f"- åŒæ­¥åŸå› : {file_info['reason']}")
                        st.write("- å»ºè®®: æ›´æ–°CKANèµ„æº")
                        st.write("- ä¼˜å…ˆçº§: ä¸­ç­‰")
            
            # æä¾›ä¸‹è½½æŠ¥å‘Š
            report_data = {
                'timestamp': datetime.now().isoformat(),
                'type': 'file_monitor',
                'summary': {
                    'total_files_checked': len(outdated_files) * 3,  # æ¨¡æ‹Ÿæ€»æ–‡ä»¶æ•°
                    'outdated_files': len(outdated_files),
                    'sync_needed': len(outdated_files) > 0
                },
                'outdated_files': outdated_files
            }
            
            if detailed_report:
                report_json = json.dumps(report_data, indent=2, ensure_ascii=False)
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½ç›‘æ§æŠ¥å‘Š",
                    data=report_json,
                    file_name=f"file_monitor_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json"
                )
        else:
            st.success("âœ… æ‰€æœ‰æ–‡ä»¶éƒ½æ˜¯æœ€æ–°çš„ï¼Œæ— éœ€åŒæ­¥")
    
    def show_usage_stats(self):
        """æ˜¾ç¤ºä½¿ç”¨ç»Ÿè®¡"""
        st.subheader("ğŸ“ˆ ä½¿ç”¨ç»Ÿè®¡")
        
        # æ¨¡æ‹Ÿç»Ÿè®¡æ•°æ®
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("æ€»å¯¼å…¥æ¬¡æ•°", "156", "12")
        
        with col2:
            st.metric("å¤„ç†æ–‡ä»¶æ•°", "2,341", "89")
        
        with col3:
            st.metric("ç›‘æ§ä»»åŠ¡", "23", "3")
        
        with col4:
            st.metric("æˆåŠŸç‡", "98.7%", "0.5%")
    
    def show_recent_activity(self):
        """æ˜¾ç¤ºæœ€è¿‘æ´»åŠ¨"""
        st.subheader("ğŸ•’ æœ€è¿‘æ´»åŠ¨")
        
        # ä»session logsè·å–æœ€è¿‘æ´»åŠ¨
        if st.session_state.logs:
            recent_logs = st.session_state.logs[-5:]
            
            for log in reversed(recent_logs):
                timestamp = log['timestamp']
                message = log['message']
                log_type = log['type']
                
                # é€‰æ‹©å›¾æ ‡
                icon = "âœ…" if log_type == "success" else "âŒ" if log_type == "error" else "âš ï¸" if log_type == "warning" else "â„¹ï¸"
                
                st.write(f"{icon} **{timestamp}** - {message}")
        else:
            st.info("æš‚æ— æ´»åŠ¨è®°å½•")
    
    def show_monitor_history(self):
        """æ˜¾ç¤ºç›‘æ§å†å²"""
        st.subheader("ğŸ“Š ç›‘æ§å†å²")
        
        df_history = pd.DataFrame(history_data)
        st.dataframe(df_history, use_container_width=True)

# è¿è¡Œåº”ç”¨
if __name__ == "__main__":
    app = CKANToolsApp()
    app.main()